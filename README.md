# 25_3
25-3 Portfolio project on optimising a model for real-life data


Sources of potential bias in data include :

•	Cognitive Bias or Implicit Bias, e.g., the creation of data or how data is weighted based on a person’s personal experiences and preferences which may 
  cause discrimination or prejudice toward a particular group or individual  
•	Sampling Bias, Measurement Bias or Exclusion Bias, e.g., the data is inaccurate through inclusion of outliers, incorrect data, duplicate data and noise,  
  or is skewed with over or under-represented groups  
•	Confirmation Bias, i.e., selecting information that is supportive of or confirms something known or believed and not data that would contradict such 
  beliefs  
•	Overfitting or Temporal Bias, i.e., the algorithm / model is overfitted to the training data or the model is trained at a point in time but does not 
  predict accurate results at a future point in time.  
•	Algorithmic Bias, i.e., bias integrated into the algorithm that processes the data through, for example, programming errors, inaccurate weighting or 
  through the developers conscious or unconscious bias being integrated into the algorithm’s decision-making process
  
Such biases can result in harms to :

•	Individuals, e.g., in employment opportunities, housing, education, credit applications and privacy
•	Harms to Groups e.g., facial recognition, mass surveillance, civil rights
•	Societies, e.g., disinformation, safety
•	Companies and Institutions, e.g., reputational, economic, legal and regulatory

What actions could you take to mitigate discrimination in the data you use or models you create? 

Actions to mitigate discrimination in the data used or inherent in models would include :

•	Ensuring laws and regulations are complied with, for example the EU AI Act 
  https://www.europarl.europa.eu/news/en/headlines/society/20230601STO93804/eu-ai-act-first-regulation-on-artificial-intelligence
•	Ensuring ethical frameworks, guidance and blueprints are followed, for example 
  2019: OECD AI principles, 2021: White House Office of Science and Technology Policy Blueprint for an AI Bill of Rights, United Nations Educational, 
  Scientific and Cultural Organization (UNESCO) Principles, Asilomar AI Principles, Institute of Electrical and Electronics Engineers (IEEE) Initiative on 
  Ethics of Autonomous and Intelligent Systems, Commission Nationale de l'Informatique et des Libertés (CNIL) AI Action Plan
•	Develop organisational policies, procedures and oversight through a cross-functional diverse governance and risk management functions 
•	Ensure appropriate training for machine learning and AI resources
•	Ensure an appropriate degree of interpretability of data and models, i.e., that they can be understood by a human actor
•	Ensure an appropriate degree of visibility of data and models, for example how data is selected and then cleansed and assumptions / factors influencing 
  the ten steps of the machine learning project development model
•	Use techniques to ensure predictive fairness (no systemic differences based on race, age , gender, disability etc) and equal opportunity through measure 
  such as removing protected attributes such as race or gender (feature binding), accounting for the lack of available data in under-represented groups 
  (e.g. monotonic select risk, MIT) and optimising the accuracy of models
•	Use metrics to measure the level of bias and the ability to remove such bias through machine learning related capability models, ongoing assessments and 
  audits
•	Ensure continual improvement in capabilities to analyse and remove bias

The machine learner has a responsibility to ensure data and models fairly represent lived realities to :

•	Comply with current and emerging laws, regulations, risk management frameworks and standards e.g., EU AI Act, Council of Europe Human Rights, Democracy, 
  and the Rule of Law Assurance Framework for AI Systems (HUDERIA)
•	Adhere to moral, ethical and professional standards
•	Ensure unjustified harms to individuals, groups, societies, companies and institutions are prevented or risks of such harm are minimised 
•	Ensure ‘transparency, explainability, repeatability/reproducibility, safety, security, robustness, fairness’ as well as
  appropriate elements of ‘governance, accountability, human agency and oversight, inclusive growth, societal and environmental well-being’ (Singapore’s 
  Model AI Framework)

Additional References

https://www.ibm.com/blog/shedding-light-on-ai-bias-with-real-world-examples/
International Association of Privacy Professionals (IAPP), Artificial Intelligence Governance Professional
https://www.techtarget.com/searchenterpriseai/feature/6-ways-to-reduce-different-types-of-bias-in-machine-learning
International Association of Privacy Professionals (IAPP), Artificial Intelligence Governance Professional
